CONTEXT: FILE: fastapi_server/legacy/api/routes/toolchain.py
BRANCH: 06-chapter__backend-frontend-retrospective

# LEARNING EXAMPLE ONLY - NOT FOR PRODUCTION

# pyright: reportGeneralTypeIssues=false
# pyright: reportMissingImports=false
# pyright: reportUndefinedVariable=false
# pyright: reportMissingTypeStubs=false
# pyright: reportUnknownMemberType=false
# pyright: reportUnknownVariableType=false
# pyright: reportUnknownArgumentType=false
# pyright: reportUnknownLambdaType=false
# pyright: reportUnknownParameterType=false
# pyright: reportOptionalMemberAccess=false
# pyright: reportOptionalSubscript=false
# pyright: reportOptionalCall=false
# pyright: reportOptionalIterable=false
# pyright: reportOptionalContextManager=false
# pyright: reportOptionalOperand=false
# pyright: reportGeneralTypeIssues=false
# pyright: reportMissingImports=false

from typing import Any, Dict, Union

from fastapi import APIRouter, HTTPException
from fastapi.responses import Response, StreamingResponse
from models.llm_request import LLMRequest

from api.config.model_routes import model_map, model_service_map
from api.handlers.toolchain_runner import run_toolchain_logic

router = APIRouter()


@router.post("/tool_toolchain/v1", response_model=None)
async def handle_chat(
    payload: LLMRequest,
) -> Union[Dict[str, Any], Response, StreamingResponse]:
    """Handle atomic tool execution requests (single stage)"""

    # Validate model exists in our config
    if payload.model_container not in model_map:
        raise HTTPException(
            status_code=400,
            detail=f"Unknown model: {payload.model_container}. Available models: {list(model_map.keys())}",
        )

    # Get the actual model name from our config
    actual_model_name = model_map[payload.model_container]
    if not actual_model_name:
        raise HTTPException(
            status_code=400,
            detail=f"Model {payload.model_container} is not configured. Check environment variables.",
        )

    # Get the base URL from our config
    base_url = model_service_map.get(payload.model_container)
    if not base_url:
        raise HTTPException(
            status_code=400, detail=f"No service configured for model: {payload.model_container}"
        )

    # Add /v1 suffix to base URL
    full_base_url = f"{base_url}/v1"

    # Call the atomic execution logic with centralized config
    result = await run_toolchain_logic(
        stage_id=payload.stage_id,
        base_url=full_base_url,
        model_name=actual_model_name,
        stream=payload.stream,
        user_prompt=payload.user_prompt,
        system_prompt=payload.system_prompt,
        max_tokens=payload.max_tokens,
        temperature=payload.temperature,
        synthesis=payload.synthesis,
    )

    return result
